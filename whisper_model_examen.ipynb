{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d795f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from jiwer import wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f28e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mount to our Google Drive, granting access and log-in required\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96509589",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the whisper-small version, best for our hardware\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6dfcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Path to dataset on our drive\n",
    "ROOT_PATHS = {\n",
    "    \"swedia_kristianstad\": \"/content/drive/MyDrive/ml-computers/Swedia_Kristianstad\",\n",
    "    \"swedia_sormland\": \"/content/drive/MyDrive/ml-computers/Swedia_Sormland\"\n",
    "}\n",
    "MAX_SEGMENTS_PER_DIALECT = 20 # set segments appropriate for hardware limitations ex. 20\n",
    "MAX_LABEL_LENGTH = 440\n",
    "TOKEN_SLICE_LENGTH = 440\n",
    "LABEL_MAP = {\"swedia_kristianstad\": 1, \"swedia_sormland\": 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ce716",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Help functions for ex. finding audio + textgrid pairs\n",
    "def find_wav_textgrid_pairs(root_path, max_segments):\n",
    "    pairs = []\n",
    "    count = 0\n",
    "    for subdir, _, files in os.walk(root_path):\n",
    "        if \"spontaneous\" in subdir:\n",
    "            wav_files = [f for f in files if f.endswith(\".wav\") and not f.startswith(\"._\")]\n",
    "            textgrid_files = [f for f in files if f.endswith(\".TextGrid\") and not f.startswith(\"._\")]\n",
    "            for wav_file in wav_files:\n",
    "                if count >= max_segments:\n",
    "                    break\n",
    "                base = wav_file.replace(\".wav\", \"\")\n",
    "                if base + \".TextGrid\" in textgrid_files:\n",
    "                    pairs.append((os.path.join(subdir, wav_file), os.path.join(subdir, base + \".TextGrid\")))\n",
    "                    count += 1\n",
    "    return pairs\n",
    "\n",
    "def read_textgrid(file_path, processor):\n",
    "    intervals = []\n",
    "    encodings = [\"utf-8\", \"iso-8859-1\", \"windows-1252\"]\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=enc) as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if 'text = \"' in line:\n",
    "                        match = re.findall(r'text = \"(.*)\"', line)\n",
    "                        if match:\n",
    "                            text = match[0].strip()\n",
    "                            if text:\n",
    "                                intervals.append(text)\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "\n",
    "    full_text = \" \".join(intervals)\n",
    "    tokenized = processor.tokenizer(full_text).input_ids\n",
    "    if len(tokenized) <= MAX_LABEL_LENGTH:\n",
    "        return full_text\n",
    "    else:\n",
    "        short_tokens = tokenized[:TOKEN_SLICE_LENGTH]\n",
    "        return processor.tokenizer.decode(short_tokens, skip_special_tokens=True)\n",
    "\n",
    "def extract_data(root_paths, max_segments, processor):\n",
    "    data = []\n",
    "    for dialect, path in root_paths.items():\n",
    "        pairs = find_wav_textgrid_pairs(path, max_segments)\n",
    "        print(f\"Found {len(pairs)} pairs for {dialect}\")\n",
    "        for wav, tg in pairs:\n",
    "            sentence = read_textgrid(tg, processor)\n",
    "            data.append({\n",
    "                \"path\": wav,\n",
    "                \"sentence\": sentence,\n",
    "                \"dialect\": dialect,\n",
    "                \"dialect_label\": LABEL_MAP[dialect]\n",
    "            })\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317795e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing for the ASR-training\n",
    "def preprocess_for_training(batch):\n",
    "    audio, _ = librosa.load(batch[\"path\"], sr=16000)\n",
    "    input_features = processor(audio, sampling_rate=16000).input_features[0]\n",
    "    labels = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
    "    batch[\"input_features\"] = input_features\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b011a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing for our classification task\n",
    "def preprocess_for_classification(batch):\n",
    "    audio, _ = librosa.load(batch[\"path\"], sr=16000)\n",
    "    inputs = processor(audio, sampling_rate=16000)\n",
    "    batch[\"input_features\"] = inputs.input_features[0]\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
    "    batch[\"dialect_label\"] = batch[\"dialect_label\"]\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae8120",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract and split data train/test 80/20\n",
    "data = extract_data(ROOT_PATHS, MAX_SEGMENTS_PER_DIALECT, processor)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee037a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing datasets for ASR training and for classification\n",
    "train_dataset_for_training = Dataset.from_list(train_data).map(preprocess_for_training)\n",
    "test_dataset_for_training = Dataset.from_list(test_data).map(preprocess_for_training)\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data).map(preprocess_for_classification, remove_columns=[\"path\", \"sentence\", \"dialect\"])\n",
    "test_dataset = Dataset.from_list(test_data).map(preprocess_for_classification, remove_columns=[\"path\", \"sentence\", \"dialect\"])\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be74dc4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Toggle training on/off for off set = FALSE\n",
    "TRAIN_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591478a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Custom collator for padding labels with -100\n",
    "def custom_data_collator(features):\n",
    "    input_features = torch.stack([torch.tensor(f[\"input_features\"]) for f in features])\n",
    "    labels = [torch.tensor(f[\"labels\"]) for f in features]\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "    return {\"input_features\": input_features, \"labels\": padded_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8d77f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Runs training if \"TRAIN_MODEL = TRUE\"\n",
    "if TRAIN_MODEL:\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper_finetuned_skanska\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",        # Log steps\n",
    "    logging_steps=1,                 # Log every step\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset_for_training,\n",
    "        eval_dataset=test_dataset_for_training,\n",
    "        tokenizer=processor,\n",
    "        data_collator=custom_data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fea741",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Save the modell and processor\n",
    "    model.save_pretrained(\"./whisper_finetuned_skanska\")\n",
    "    processor.save_pretrained(\"./whisper_finetuned_skanska\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb534ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Classification\n",
    "X_train = [np.array(x).flatten() for x in train_dataset[\"input_features\"]]\n",
    "X_test = [np.array(x).flatten() for x in test_dataset[\"input_features\"]]\n",
    "y_train = train_dataset[\"dialect_label\"]\n",
    "y_test = test_dataset[\"dialect_label\"]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "acc = np.mean([p == r for p, r in zip(y_pred, y_test)])\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"\\n Dialect Classification with PCA + LogisticRegression\")\n",
    "print(f\" Accuracy: {acc:.2%}\")\n",
    "print(f\" F1 Score: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb58b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function for evaluation\n",
    "def compute_metrics(dataset, model, processor, clf, pca):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    dialect_preds = []\n",
    "    dialect_refs = []\n",
    "\n",
    "    for example in dataset:\n",
    "        input_tensor = torch.tensor(example[\"input_features\"]).unsqueeze(0).to(model.device)\n",
    "        predicted_ids = model.generate(input_tensor)\n",
    "        transcription = processor.tokenizer.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "        true_transcription = processor.tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n",
    "\n",
    "        predictions.append(transcription.lower())\n",
    "        references.append(true_transcription.lower())\n",
    "\n",
    "        input_flat = np.array(example[\"input_features\"]).flatten().reshape(1, -1)\n",
    "        input_pca = pca.transform(input_flat)\n",
    "        dialect_pred = clf.predict(input_pca)[0]\n",
    "\n",
    "        dialect_preds.append(dialect_pred)\n",
    "        dialect_refs.append(example[\"dialect_label\"])\n",
    "\n",
    "    for i in range(min(2, len(predictions))):\n",
    "        print(f\"\\n Reference   : {references[i]}\\n Prediction : {predictions[i]}\")\n",
    "\n",
    "    wer_score = wer(references, predictions)\n",
    "    cer_score = cer(references, predictions)\n",
    "    acc = np.mean([p == r for p, r in zip(dialect_preds, dialect_refs)])\n",
    "    f1 = f1_score(dialect_refs, dialect_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n WER: {wer_score:.2%}\")\n",
    "    print(f\" CER: {cer_score:.2%}\")\n",
    "    print(f\" Dialect Accuracy: {acc:.2%}\")\n",
    "    print(f\" Dialect F1 Score: {f1:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ef257",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run evaluation function\n",
    "compute_metrics(test_dataset, model, processor, clf, pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f033d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
